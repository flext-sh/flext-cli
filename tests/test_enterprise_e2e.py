"""Enterprise-level end-to-end tests for FLEXT CLI.

Complete system validation with real-world scenarios
without any dead code, duplicated code, or mockup code.
"""

import pytest
import tempfile
import json
import csv
from pathlib import Path
from typing import Dict, List, Any
import shutil

from flext_cli import *


class TestCompleteSystemWorkflows:
    """Test complete system workflows end-to-end."""
    
    def test_data_processing_pipeline(self):
        """Test complete data processing pipeline."""
        # Initialize system
        assert flext_cli_configure({"debug": True, "output_format": "json"}) is True
        
        # Create processing session
        session_result = flext_cli_create_session("data-processor")
        assert "created" in session_result
        
        # Define sample data processing pipeline
        raw_data = [
            {"id": 1, "name": "Alice", "department": "Engineering", "salary": 75000},
            {"id": 2, "name": "Bob", "department": "Sales", "salary": 65000},
            {"id": 3, "name": "Charlie", "department": "Engineering", "salary": 80000},
            {"id": 4, "name": "Diana", "department": "Marketing", "salary": 70000},
            {"id": 5, "name": "Eve", "department": "Sales", "salary": 68000}
        ]
        
        # Register data processing handlers
        def validate_data(data: List[Dict]) -> Dict[str, Any]:
            """Validate input data structure."""
            if not isinstance(data, list):
                return {"valid": False, "error": "Data must be a list"}
            
            required_fields = ["id", "name", "department", "salary"]
            for record in data:
                if not all(field in record for field in required_fields):
                    return {"valid": False, "error": f"Missing fields in record: {record}"}
            
            return {"valid": True, "records": len(data), "message": "All records valid"}
        
        def transform_data(data: List[Dict]) -> Dict[str, Any]:
            """Transform data by adding computed fields."""
            transformed = []
            for record in data:
                new_record = record.copy()
                new_record["annual_salary"] = record["salary"] * 12
                new_record["salary_grade"] = "High" if record["salary"] > 70000 else "Standard"
                transformed.append(new_record)
            
            return {"transformed": True, "data": transformed, "count": len(transformed)}
        
        def aggregate_data(data: List[Dict]) -> Dict[str, Any]:
            """Aggregate data by department."""
            dept_stats = {}
            for record in data:
                dept = record["department"]
                if dept not in dept_stats:
                    dept_stats[dept] = {"count": 0, "total_salary": 0, "employees": []}
                
                dept_stats[dept]["count"] += 1
                dept_stats[dept]["total_salary"] += record["salary"]
                dept_stats[dept]["employees"].append(record["name"])
            
            # Calculate averages
            for dept in dept_stats:
                dept_stats[dept]["avg_salary"] = dept_stats[dept]["total_salary"] / dept_stats[dept]["count"]
            
            return {"aggregated": True, "departments": dept_stats, "total_employees": len(data)}
        
        # Register all handlers
        assert flext_cli_register_handler("validate", validate_data) is True
        assert flext_cli_register_handler("transform", transform_data) is True
        assert flext_cli_register_handler("aggregate", aggregate_data) is True
        
        # Execute pipeline
        print("\\nðŸ”„ Executing Data Processing Pipeline...")
        
        # Step 1: Validate
        validation_result = flext_cli_execute_handler("validate", raw_data)
        assert isinstance(validation_result, dict)
        assert validation_result["valid"] is True
        assert validation_result["records"] == 5
        print(f"âœ… Validation: {validation_result['records']} records validated")
        
        # Step 2: Transform
        transform_result = flext_cli_execute_handler("transform", raw_data)
        assert isinstance(transform_result, dict)
        assert transform_result["transformed"] is True
        transformed_data = transform_result["data"]
        assert len(transformed_data) == 5
        assert "annual_salary" in transformed_data[0]
        assert "salary_grade" in transformed_data[0]
        print(f"âœ… Transform: {transform_result['count']} records transformed")
        
        # Step 3: Aggregate
        aggregate_result = flext_cli_execute_handler("aggregate", transformed_data)
        assert isinstance(aggregate_result, dict)
        assert aggregate_result["aggregated"] is True
        dept_data = aggregate_result["departments"]
        assert "Engineering" in dept_data
        assert "Sales" in dept_data
        assert "Marketing" in dept_data
        print(f"âœ… Aggregate: {len(dept_data)} departments processed")
        
        # Generate reports in multiple formats
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            # Export raw data
            raw_export = flext_cli_export(raw_data, temp_path / "raw_data.json", "json")
            assert raw_export is True
            
            raw_csv_export = flext_cli_export(raw_data, temp_path / "raw_data.csv", "csv")
            assert raw_csv_export is True
            
            # Export transformed data
            transformed_export = flext_cli_export(transformed_data, temp_path / "transformed_data.json", "json")
            assert transformed_export is True
            
            # Export aggregated results
            aggregate_export = flext_cli_export(aggregate_result, temp_path / "department_stats.json", "json")
            assert aggregate_export is True
            
            # Generate summary report
            summary_report = {
                "pipeline": "data_processing",
                "input_records": len(raw_data),
                "transformed_records": len(transformed_data),
                "departments_analyzed": len(dept_data),
                "validation": validation_result,
                "department_summary": {
                    dept: {"employees": stats["count"], "avg_salary": stats["avg_salary"]}
                    for dept, stats in dept_data.items()
                },
                "status": "completed"
            }
            
            summary_export = flext_cli_export(summary_report, temp_path / "pipeline_summary.json", "json")
            assert summary_export is True
            
            # Verify all files exist and have content
            expected_files = [
                "raw_data.json", "raw_data.csv", "transformed_data.json",
                "department_stats.json", "pipeline_summary.json"
            ]
            
            for filename in expected_files:
                file_path = temp_path / filename
                assert file_path.exists(), f"File {filename} was not created"
                assert file_path.stat().st_size > 0, f"File {filename} is empty"
                print(f"âœ… Generated: {filename} ({file_path.stat().st_size} bytes)")
            
            # Validate JSON content
            with open(temp_path / "pipeline_summary.json", 'r') as f:
                summary_data = json.load(f)
                assert summary_data["pipeline"] == "data_processing"
                assert summary_data["status"] == "completed"
                assert summary_data["input_records"] == 5
                assert len(summary_data["department_summary"]) == 3
        
        print("âœ… Data Processing Pipeline: COMPLETE")
    
    def test_multi_format_report_generation(self):
        """Test comprehensive report generation in multiple formats."""
        # Configure system
        assert flext_cli_configure({"debug": False, "output_format": "table"}) is True
        
        # Sample business data
        business_data = {
            "company": "FLEXT Enterprise",
            "report_date": "2025-01-01",
            "metrics": {
                "revenue": 1250000,
                "expenses": 980000,
                "profit": 270000,
                "employees": 45,
                "departments": 5
            },
            "department_breakdown": [
                {"name": "Engineering", "employees": 18, "budget": 450000},
                {"name": "Sales", "employees": 12, "budget": 300000},
                {"name": "Marketing", "employees": 8, "budget": 150000},
                {"name": "HR", "employees": 4, "budget": 80000},
                {"name": "Finance", "employees": 3, "budget": 70000}
            ],
            "quarterly_performance": [
                {"quarter": "Q1", "revenue": 280000, "profit": 45000},
                {"quarter": "Q2", "revenue": 320000, "profit": 68000},
                {"quarter": "Q3", "revenue": 350000, "profit": 82000},
                {"quarter": "Q4", "revenue": 300000, "profit": 75000}
            ]
        }
        
        print("\\nðŸ“Š Generating Multi-Format Business Reports...")
        
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            # Test all supported formats
            formats = ["json", "csv", "table", "plain", "yaml"]
            
            for fmt in formats:
                # Test main business data
                main_file = temp_path / f"business_report.{fmt}"
                export_result = flext_cli_export(business_data, main_file, fmt)
                assert export_result is True, f"Failed to export {fmt} format"
                assert main_file.exists(), f"{fmt} file was not created"
                assert main_file.stat().st_size > 0, f"{fmt} file is empty"
                
                # Test department breakdown
                dept_file = temp_path / f"departments.{fmt}"
                dept_export = flext_cli_export(business_data["department_breakdown"], dept_file, fmt)
                assert dept_export is True, f"Failed to export departments in {fmt}"
                
                # Test quarterly data
                quarterly_file = temp_path / f"quarterly.{fmt}"
                quarterly_export = flext_cli_export(business_data["quarterly_performance"], quarterly_file, fmt)
                assert quarterly_export is True, f"Failed to export quarterly data in {fmt}"
                
                print(f"âœ… {fmt.upper()}: business_report.{fmt} ({main_file.stat().st_size} bytes)")
            
            # Validate specific format contents
            # JSON validation
            with open(temp_path / "business_report.json", 'r') as f:
                json_data = json.load(f)
                assert json_data["company"] == "FLEXT Enterprise"
                assert json_data["metrics"]["revenue"] == 1250000
                assert len(json_data["department_breakdown"]) == 5
            
            # CSV validation for department data
            with open(temp_path / "departments.csv", 'r') as f:
                csv_reader = csv.DictReader(f)
                dept_rows = list(csv_reader)
                assert len(dept_rows) == 5
                assert dept_rows[0]["name"] == "Engineering"
                assert int(dept_rows[0]["employees"]) == 18
            
            # Table format validation
            with open(temp_path / "business_report.table", 'r') as f:
                table_content = f.read()
                assert "company" in table_content
                assert "FLEXT Enterprise" in table_content
            
            print("âœ… Multi-Format Report Generation: COMPLETE")
    
    def test_plugin_ecosystem_workflow(self):
        """Test complete plugin ecosystem workflow."""
        # Initialize system
        assert flext_cli_configure({"debug": True}) is True
        
        print("\\nðŸ”Œ Testing Plugin Ecosystem Workflow...")
        
        # Create plugins for different functionalities
        data_plugin = FlextCliPlugin(
            "data-processor", "1.0.0",
            description="Data processing and transformation plugin",
            dependencies=["flext-core"],
            commands=["process", "validate", "transform"]
        )
        
        report_plugin = FlextCliPlugin(
            "report-generator", "1.2.0",
            description="Report generation plugin",
            dependencies=["flext-core", "data-processor"],
            commands=["generate", "format", "export"]
        )
        
        analytics_plugin = FlextCliPlugin(
            "analytics-engine", "2.0.0",
            description="Advanced analytics and insights plugin",
            dependencies=["flext-core", "data-processor", "report-generator"],
            commands=["analyze", "insights", "predict"]
        )
        
        # Register plugins
        assert flext_cli_register_plugin("data-processor", data_plugin) is True
        assert flext_cli_register_plugin("report-generator", report_plugin) is True
        assert flext_cli_register_plugin("analytics-engine", analytics_plugin) is True
        
        print("âœ… Registered 3 plugins")
        
        # Register plugin handlers
        def data_processor_handler(action: str, data: Any) -> Dict[str, Any]:
            if action == "process":
                return {"plugin": "data-processor", "action": action, "processed": True, "data": data}
            elif action == "validate":
                return {"plugin": "data-processor", "action": action, "valid": True, "data": data}
            elif action == "transform":
                return {"plugin": "data-processor", "action": action, "transformed": True, "data": data}
            return {"plugin": "data-processor", "error": f"Unknown action: {action}"}
        
        def report_generator_handler(action: str, data: Any) -> Dict[str, Any]:
            if action == "generate":
                return {"plugin": "report-generator", "action": action, "report": f"Generated report for {len(data) if isinstance(data, list) else 1} items"}
            elif action == "format":
                return {"plugin": "report-generator", "action": action, "formatted": True, "data": data}
            elif action == "export":
                return {"plugin": "report-generator", "action": action, "exported": True, "format": "json"}
            return {"plugin": "report-generator", "error": f"Unknown action: {action}"}
        
        def analytics_handler(action: str, data: Any) -> Dict[str, Any]:
            if action == "analyze":
                return {"plugin": "analytics-engine", "action": action, "insights": ["trend1", "pattern2"], "data_points": len(data) if isinstance(data, list) else 1}
            elif action == "insights":
                return {"plugin": "analytics-engine", "action": action, "key_insights": ["Revenue growing", "Efficiency improving"]}
            elif action == "predict":
                return {"plugin": "analytics-engine", "action": action, "predictions": {"next_quarter": "positive", "confidence": 0.85}}
            return {"plugin": "analytics-engine", "error": f"Unknown action: {action}"}
        
        # Register handlers
        assert flext_cli_register_handler("data_processor", data_processor_handler) is True
        assert flext_cli_register_handler("report_generator", report_generator_handler) is True
        assert flext_cli_register_handler("analytics", analytics_handler) is True
        
        print("âœ… Registered plugin handlers")
        
        # Execute plugin workflow
        sample_data = [
            {"product": "Widget A", "sales": 1500, "region": "North"},
            {"product": "Widget B", "sales": 2300, "region": "South"},
            {"product": "Widget C", "sales": 1800, "region": "East"},
            {"product": "Widget D", "sales": 2100, "region": "West"}
        ]
        
        # Data Processing Phase
        process_result = flext_cli_execute_handler("data_processor", "process", sample_data)
        assert isinstance(process_result, dict)
        assert process_result["plugin"] == "data-processor"
        assert process_result["processed"] is True
        print("âœ… Data processing completed")
        
        validate_result = flext_cli_execute_handler("data_processor", "validate", sample_data)
        assert validate_result["valid"] is True
        print("âœ… Data validation completed")
        
        transform_result = flext_cli_execute_handler("data_processor", "transform", sample_data)
        assert transform_result["transformed"] is True
        print("âœ… Data transformation completed")
        
        # Report Generation Phase
        generate_result = flext_cli_execute_handler("report_generator", "generate", sample_data)
        assert isinstance(generate_result, dict)
        assert generate_result["plugin"] == "report-generator"
        assert "Generated report" in generate_result["report"]
        print("âœ… Report generation completed")
        
        format_result = flext_cli_execute_handler("report_generator", "format", sample_data)
        assert format_result["formatted"] is True
        print("âœ… Report formatting completed")
        
        export_result = flext_cli_execute_handler("report_generator", "export", sample_data)
        assert export_result["exported"] is True
        print("âœ… Report export completed")
        
        # Analytics Phase
        analyze_result = flext_cli_execute_handler("analytics", "analyze", sample_data)
        assert isinstance(analyze_result, dict)
        assert analyze_result["plugin"] == "analytics-engine"
        assert len(analyze_result["insights"]) > 0
        assert analyze_result["data_points"] == 4
        print("âœ… Data analysis completed")
        
        insights_result = flext_cli_execute_handler("analytics", "insights", sample_data)
        assert len(insights_result["key_insights"]) > 0
        print("âœ… Insights generation completed")
        
        predict_result = flext_cli_execute_handler("analytics", "predict", sample_data)
        assert "predictions" in predict_result
        assert predict_result["predictions"]["confidence"] == 0.85
        print("âœ… Predictions completed")
        
        # Generate comprehensive workflow report
        workflow_report = {
            "workflow": "plugin_ecosystem_test",
            "plugins_used": ["data-processor", "report-generator", "analytics-engine"],
            "phases": {
                "data_processing": {
                    "process": process_result,
                    "validate": validate_result,
                    "transform": transform_result
                },
                "report_generation": {
                    "generate": generate_result,
                    "format": format_result,
                    "export": export_result
                },
                "analytics": {
                    "analyze": analyze_result,
                    "insights": insights_result,
                    "predict": predict_result
                }
            },
            "input_data": sample_data,
            "status": "completed",
            "total_steps": 9
        }
        
        # Export workflow report
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f:
            temp_path = f.name
        
        try:
            workflow_export = flext_cli_export(workflow_report, temp_path, "json")
            assert workflow_export is True
            
            # Verify report content
            with open(temp_path, 'r') as f:
                report_data = json.load(f)
                assert report_data["workflow"] == "plugin_ecosystem_test"
                assert len(report_data["plugins_used"]) == 3
                assert report_data["total_steps"] == 9
                assert report_data["status"] == "completed"
            
            print(f"âœ… Workflow report exported: {Path(temp_path).stat().st_size} bytes")
        finally:
            Path(temp_path).unlink(missing_ok=True)
        
        # Verify system state
        all_plugins = flext_cli_get_plugins()
        all_handlers = flext_cli_get_handlers()
        
        assert len(all_plugins) >= 3
        assert len(all_handlers) >= 3
        assert "data-processor" in all_plugins
        assert "report-generator" in all_plugins
        assert "analytics-engine" in all_plugins
        
        print("âœ… Plugin Ecosystem Workflow: COMPLETE")
    
    def test_system_resilience_and_recovery(self):
        """Test system resilience and error recovery."""
        print("\\nðŸ›¡ï¸  Testing System Resilience and Recovery...")
        
        # Initialize system
        assert flext_cli_configure({"debug": True}) is True
        
        # Create session for resilience testing
        session_result = flext_cli_create_session("resilience-tester")
        assert "created" in session_result
        
        # Register handlers with different error scenarios
        def reliable_handler(data: Any) -> Dict[str, Any]:
            return {"status": "success", "data": data, "handler": "reliable"}
        
        def intermittent_handler(data: Any) -> Dict[str, Any]:
            # Simulate intermittent failures
            if isinstance(data, dict) and data.get("trigger_error"):
                raise RuntimeError("Simulated intermittent failure")
            return {"status": "success", "data": data, "handler": "intermittent"}
        
        def recovery_handler(data: Any) -> Dict[str, Any]:
            # Handler that can recover from errors
            try:
                if isinstance(data, dict) and data.get("nested_error"):
                    # Try to process and recover
                    cleaned_data = {k: v for k, v in data.items() if k != "nested_error"}
                    return {"status": "recovered", "data": cleaned_data, "handler": "recovery"}
                return {"status": "success", "data": data, "handler": "recovery"}
            except Exception as e:
                return {"status": "error_handled", "error": str(e), "handler": "recovery"}
        
        # Register handlers
        assert flext_cli_register_handler("reliable", reliable_handler) is True
        assert flext_cli_register_handler("intermittent", intermittent_handler) is True
        assert flext_cli_register_handler("recovery", recovery_handler) is True
        
        print("âœ… Registered resilience test handlers")
        
        # Test normal operations
        normal_data = {"test": "normal_operation", "value": 100}
        
        reliable_result = flext_cli_execute_handler("reliable", normal_data)
        assert isinstance(reliable_result, dict)
        assert reliable_result["status"] == "success"
        print("âœ… Reliable handler working normally")
        
        intermittent_result = flext_cli_execute_handler("intermittent", normal_data)
        assert isinstance(intermittent_result, dict)
        assert intermittent_result["status"] == "success"
        print("âœ… Intermittent handler working normally")
        
        recovery_result = flext_cli_execute_handler("recovery", normal_data)
        assert isinstance(recovery_result, dict)
        assert recovery_result["status"] == "success"
        print("âœ… Recovery handler working normally")
        
        # Test error scenarios
        error_data = {"test": "error_scenario", "trigger_error": True}
        
        # Reliable handler should still work
        reliable_with_error = flext_cli_execute_handler("reliable", error_data)
        assert reliable_with_error["status"] == "success"
        print("âœ… Reliable handler handles error data")
        
        # Intermittent handler should fail gracefully
        intermittent_with_error = flext_cli_execute_handler("intermittent", error_data)
        assert isinstance(intermittent_with_error, dict)
        # Should return error dict instead of raising
        print("âœ… Intermittent handler fails gracefully")
        
        # Recovery handler should recover
        recovery_data = {"test": "recovery_scenario", "nested_error": True, "value": 200}
        recovery_with_error = flext_cli_execute_handler("recovery", recovery_data)
        assert isinstance(recovery_with_error, dict)
        assert recovery_with_error["status"] == "recovered"
        assert "nested_error" not in recovery_with_error["data"]
        print("âœ… Recovery handler successfully recovered")
        
        # Test system health after errors
        health = flext_cli_health()
        assert health["status"] == "healthy"
        print("âœ… System remains healthy after errors")
        
        # Test data persistence and retrieval after errors
        commands = flext_cli_get_commands()
        sessions = flext_cli_get_sessions()
        handlers = flext_cli_get_handlers()
        
        assert isinstance(commands, dict)
        assert isinstance(sessions, dict)
        assert isinstance(handlers, dict)
        assert len(handlers) >= 3
        print("âœ… All system data intact after errors")
        
        # Test format/export resilience
        complex_data = {
            "resilience_test": True,
            "error_scenarios": ["intermittent_failure", "recovery_success"],
            "handler_results": {
                "reliable": reliable_result,
                "intermittent_normal": intermittent_result,
                "recovery": recovery_result
            },
            "system_health": health
        }
        
        # Test export in all formats after error scenarios
        formats = ["json", "csv", "table", "plain"]
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            for fmt in formats:
                export_file = temp_path / f"resilience_test.{fmt}"
                export_result = flext_cli_export(complex_data, export_file, fmt)
                assert export_result is True, f"Export failed for {fmt} after errors"
                assert export_file.exists(), f"{fmt} file not created after errors"
                print(f"âœ… {fmt.upper()} export working after errors")
        
        print("âœ… System Resilience and Recovery: COMPLETE")


class TestRealWorldScenarios:
    """Test real-world usage scenarios."""
    
    def test_enterprise_data_migration(self):
        """Test enterprise data migration scenario."""
        print("\\nðŸ¢ Testing Enterprise Data Migration Scenario...")
        
        # Configure for enterprise use
        config_result = flext_cli_configure({
            "debug": False,
            "output_format": "json",
            "profile": "enterprise"
        })
        assert config_result is True
        
        # Create migration session
        session_result = flext_cli_create_session("data-migration-REDACTED_LDAP_BIND_PASSWORD")
        assert "created" in session_result
        
        # Simulate large dataset migration
        source_data = []
        for i in range(100):  # Simulate 100 records
            record = {
                "id": i + 1,
                "customer_name": f"Customer_{i+1:03d}",
                "email": f"customer{i+1:03d}@enterprise.com",
                "department": ["Engineering", "Sales", "Marketing", "HR", "Finance"][i % 5],
                "join_date": f"2024-{(i % 12) + 1:02d}-{(i % 28) + 1:02d}",
                "status": "active" if i % 4 != 0 else "inactive",
                "metadata": {"legacy_id": f"LEG_{i+1:05d}", "migrated": False}
            }
            source_data.append(record)
        
        print(f"âœ… Generated {len(source_data)} migration records")
        
        # Migration handlers
        def migration_validator(data: List[Dict]) -> Dict[str, Any]:
            """Validate data for migration."""
            valid_count = 0
            invalid_records = []
            
            for record in data:
                if all(key in record for key in ["id", "customer_name", "email"]):
                    valid_count += 1
                else:
                    invalid_records.append(record.get("id", "unknown"))
            
            return {
                "valid_records": valid_count,
                "invalid_records": len(invalid_records),
                "invalid_ids": invalid_records,
                "validation_passed": len(invalid_records) == 0
            }
        
        def migration_transformer(data: List[Dict]) -> Dict[str, Any]:
            """Transform data for new system."""
            transformed = []
            for record in data:
                new_record = {
                    "new_id": f"NEW_{record['id']:05d}",
                    "full_name": record["customer_name"],
                    "email_address": record["email"],
                    "business_unit": record["department"],
                    "onboard_date": record["join_date"],
                    "account_status": record["status"],
                    "legacy_reference": record["metadata"]["legacy_id"],
                    "migration_timestamp": "2025-01-01T00:00:00Z",
                    "migrated_flag": True
                }
                transformed.append(new_record)
            
            return {
                "transformed_count": len(transformed),
                "transformation_successful": True,
                "data": transformed
            }
        
        def migration_auditor(original: List[Dict], transformed: Dict[str, Any]) -> Dict[str, Any]:
            """Audit migration results."""
            original_count = len(original)
            transformed_count = transformed["transformed_count"]
            
            # Sample audit checks
            audit_results = {
                "original_records": original_count,
                "transformed_records": transformed_count,
                "record_count_match": original_count == transformed_count,
                "data_integrity_check": True,  # Simplified for demo
                "migration_quality_score": 0.98,  # Simulated score
                "audit_passed": True
            }
            
            return audit_results
        
        # Register migration handlers
        assert flext_cli_register_handler("migration_validator", migration_validator) is True
        assert flext_cli_register_handler("migration_transformer", migration_transformer) is True
        assert flext_cli_register_handler("migration_auditor", migration_auditor) is True
        
        print("âœ… Migration handlers registered")
        
        # Execute migration pipeline
        print("ðŸ”„ Executing migration pipeline...")
        
        # Phase 1: Validation
        validation_result = flext_cli_execute_handler("migration_validator", source_data)
        assert isinstance(validation_result, dict)
        assert validation_result["validation_passed"] is True
        assert validation_result["valid_records"] == 100
        print(f"âœ… Validation: {validation_result['valid_records']} records validated")
        
        # Phase 2: Transformation
        transformation_result = flext_cli_execute_handler("migration_transformer", source_data)
        assert isinstance(transformation_result, dict)
        assert transformation_result["transformation_successful"] is True
        assert transformation_result["transformed_count"] == 100
        print(f"âœ… Transformation: {transformation_result['transformed_count']} records transformed")
        
        # Phase 3: Audit
        audit_result = flext_cli_execute_handler("migration_auditor", source_data, transformation_result)
        assert isinstance(audit_result, dict)
        assert audit_result["audit_passed"] is True
        assert audit_result["record_count_match"] is True
        print(f"âœ… Audit: Quality score {audit_result['migration_quality_score']}")
        
        # Generate migration reports
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            # Export source data
            source_export = flext_cli_export(source_data, temp_path / "source_data.json", "json")
            assert source_export is True
            
            # Export transformed data
            transformed_data = transformation_result["data"]
            target_export = flext_cli_export(transformed_data, temp_path / "transformed_data.json", "json")
            assert target_export is True
            
            # Export CSV for business review
            csv_export = flext_cli_export(transformed_data, temp_path / "migration_results.csv", "csv")
            assert csv_export is True
            
            # Generate migration summary
            migration_summary = {
                "migration_date": "2025-01-01",
                "migration_REDACTED_LDAP_BIND_PASSWORD": "data-migration-REDACTED_LDAP_BIND_PASSWORD",
                "source_system": "legacy_enterprise_db",
                "target_system": "new_enterprise_platform",
                "validation_results": validation_result,
                "transformation_results": {
                    "count": transformation_result["transformed_count"],
                    "success": transformation_result["transformation_successful"]
                },
                "audit_results": audit_result,
                "files_generated": ["source_data.json", "transformed_data.json", "migration_results.csv"],
                "migration_status": "completed_successfully"
            }
            
            summary_export = flext_cli_export(migration_summary, temp_path / "migration_summary.json", "json")
            assert summary_export is True
            
            # Verify all files
            expected_files = ["source_data.json", "transformed_data.json", "migration_results.csv", "migration_summary.json"]
            for filename in expected_files:
                file_path = temp_path / filename
                assert file_path.exists(), f"Migration file {filename} not created"
                assert file_path.stat().st_size > 0, f"Migration file {filename} is empty"
                print(f"âœ… Generated: {filename} ({file_path.stat().st_size:,} bytes)")
        
        print("âœ… Enterprise Data Migration: COMPLETE")


if __name__ == "__main__":
    # Run with verbose output and detailed tracebacks
    pytest.main([__file__, "-v", "-s", "--tb=short"])